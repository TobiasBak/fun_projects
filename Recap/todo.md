


# All missing implementations


## Major steps
1. Subtitles
2. Combine the images and the voiceover into a video. 
3. Implement a method for combining the videos into a single video.
4. Thumbnails, that are auto generated based on language of the video. 

## Improvements
1. Use a background for the video, such that adhd viewers stay
This background could be a rainy forest etc.    
2. Some images are too large 1.8k+ pixels in height before they are resized. 
Create a script that determines an optimal point somewhere in the middle, where the picture can be split.
A determination could be the amount of white or black pixels in the image at that point in the middle.
3. Timings to see what is slow
4. Possible replace all her/his with "the persons"
5. Open pages instead of new browsers
6. Multithread timings

## Conquer the world
1. Translate to different languages. (Indian, Spanish, Russian, Arabic, etc.)






possible image describers:
1. https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/visual_captioning.ipynb
2. https://huggingface.co/Salesforce/blip2-opt-2.7b (local model)




pip install requests requests-toolbelt

